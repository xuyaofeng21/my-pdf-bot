import streamlit as st
from pypdf import PdfReader

# === ğŸ›¡ï¸ ç¨³å®šç‰ˆ(0.1.x) ç»å…¸å¼•ç”¨å†™æ³• ===
# è¿™äº›è·¯å¾„åœ¨ LangChain 0.1.20 ç‰ˆæœ¬é‡Œæ˜¯ç»å¯¹å­˜åœ¨çš„
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain_community.vectorstores import Chroma
from langchain_community.chat_models import ChatOpenAI
from langchain.chains import RetrievalQA
# ==========================================

import os

# --- 1. é¡µé¢é…ç½® ---
st.set_page_config(page_title="å¤šæ–‡ä»¶ AI åŠ©æ‰‹", layout="wide")
st.title("ğŸ“š å¤šæ–‡æ¡£ AI æ™ºèƒ½é—®ç­”åŠ©æ‰‹")

# --- 2. ä¾§è¾¹æ  ---
with st.sidebar:
    st.header("âš™ï¸ è®¾ç½®")

    api_key = None
    if "DEEPSEEK_API_KEY" in st.secrets:
        api_key = st.secrets["DEEPSEEK_API_KEY"]
        st.success("âœ… äº‘ç«¯å¯†é’¥å·²æ¿€æ´»")
    else:
        api_key = st.text_input("DeepSeek API Key", type="password")

    st.markdown("---")
    uploaded_files = st.file_uploader("ä¸Šä¼  PDF", type=["pdf"], accept_multiple_files=True)
    process_button = st.button("ğŸš€ å¼€å§‹åˆ†æ")


# --- 3. æ ¸å¿ƒåŠŸèƒ½ ---
def get_pdf_text(pdf_docs):
    text = ""
    for pdf in pdf_docs:
        pdf_reader = PdfReader(pdf)
        for page in pdf_reader.pages:
            t = page.extract_text()
            if t: text += t
    return text


def get_text_chunks(text):
    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)
    chunks = text_splitter.split_text(text)
    return chunks


def get_vector_store(text_chunks):
    # ä½¿ç”¨æœ¬åœ°æ¨¡å‹ï¼Œè§„é¿ OpenAiEmbeddings æ”¶è´¹é—®é¢˜
    embeddings = HuggingFaceEmbeddings(model_name="all-MiniLM-L6-v2")
    vector_store = Chroma.from_texts(text_chunks, embedding=embeddings)
    return vector_store


# --- 4. æ‰§è¡Œé€»è¾‘ ---
if process_button and uploaded_files and api_key:
    with st.spinner("æ­£åœ¨å¤„ç†æ–‡æ¡£..."):
        raw_text = get_pdf_text(uploaded_files)
        text_chunks = get_text_chunks(raw_text)
        vector_store = get_vector_store(text_chunks)
        st.session_state.vector_store = vector_store
        st.success("âœ… å¤„ç†å®Œæˆï¼")

# --- 5. é—®ç­”é€»è¾‘ ---
if "vector_store" in st.session_state:
    st.markdown("### ğŸ’¬ æé—®")
    user_question = st.text_input("ä½ æƒ³é—®ä»€ä¹ˆï¼Ÿ")

    if user_question:
        llm = ChatOpenAI(
            api_key=api_key,
            base_url="https://api.deepseek.com/v1",
            model_name="deepseek-chat",
            temperature=0.3
        )

        qa_chain = RetrievalQA.from_chain_type(
            llm=llm,
            retriever=st.session_state.vector_store.as_retriever(),
            return_source_documents=True
        )

        response = qa_chain.invoke({"query": user_question})

        st.write("ğŸ¤– **AI å›ç­”:**")
        st.write(response["result"])

        with st.expander("æŸ¥çœ‹æ¥æº"):
            for doc in response["source_documents"]:
                st.write(doc.page_content)
else:
    if not uploaded_files:
        st.info("ğŸ‘ˆ è¯·å…ˆåœ¨å·¦ä¾§ä¸Šä¼  PDF æ–‡ä»¶")