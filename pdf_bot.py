import streamlit as st
from PyPDF2 import PdfReader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain_community.vectorstores import Chroma
from langchain_community.chat_models import ChatOpenAI
from langchain.chains import RetrievalQA
import os

# --- 1. é¡µé¢åŸºç¡€è®¾ç½® ---
st.set_page_config(page_title="å¤šæ–‡ä»¶ AI åŠ©æ‰‹", layout="wide")
st.title("ğŸ“š å¤šæ–‡æ¡£ AI æ™ºèƒ½é—®ç­”åŠ©æ‰‹")

# --- 2. ä¾§è¾¹æ ï¼šå®‰å…¨ Key + å¤šæ–‡ä»¶ä¸Šä¼  ---
with st.sidebar:
    st.header("âš™ï¸ è®¾ç½®é¢æ¿")

    # === ğŸ”’ å®‰å…¨æ”¹è¿›éƒ¨åˆ† Start ===
    # é€»è¾‘ï¼šä¼˜å…ˆè¯» Secretsï¼Œä¸æŠŠ Key æ˜¾ç¤ºåœ¨è¾“å…¥æ¡†é‡Œ
    api_key = None

    if "DEEPSEEK_API_KEY" in st.secrets:
        # å¦‚æœäº‘ç«¯æœ‰ Keyï¼Œç›´æ¥ç”¨ï¼Œä¸å›æ˜¾
        api_key = st.secrets["DEEPSEEK_API_KEY"]
        st.success("âœ… äº‘ç«¯å¯†é’¥å·²æ¿€æ´»")
        st.info("ç³»ç»Ÿå·²è‡ªåŠ¨åŠ è½½å¯†é’¥ï¼Œæ— éœ€æ‰‹åŠ¨è¾“å…¥ã€‚")
    else:
        # å¦‚æœæ²¡æœ‰ï¼Œæ‰æ˜¾ç¤ºè¾“å…¥æ¡†
        api_key = st.text_input("è¯·è¾“å…¥ DeepSeek API Key", type="password")
        if not api_key:
            st.warning("âš ï¸ è¯·è¾“å…¥å¯†é’¥ä»¥å¼€å§‹ä½¿ç”¨")
    # === ğŸ”’ å®‰å…¨æ”¹è¿›éƒ¨åˆ† End ===

    st.markdown("---")

    # === ğŸ“‚ å¤šæ–‡ä»¶æ”¹è¿›éƒ¨åˆ† Start ===
    # accept_multiple_files=True å…è®¸é€‰å¤šä¸ª
    uploaded_files = st.file_uploader(
        "ä¸Šä¼  PDF æ–‡ä»¶ (æ”¯æŒå¤šä¸ª)",
        type=["pdf"],
        accept_multiple_files=True
    )
    # === ğŸ“‚ å¤šæ–‡ä»¶æ”¹è¿›éƒ¨åˆ† End ===

    process_button = st.button("ğŸš€ å¼€å§‹åˆ†ææ–‡æ¡£")


# --- 3. æ ¸å¿ƒå‡½æ•°ï¼šå¤„ç†å¤šä¸ª PDF ---
def get_pdf_text(pdf_docs):
    text = ""
    # å¾ªç¯éå†æ¯ä¸€ä¸ªä¸Šä¼ çš„æ–‡ä»¶
    for pdf in pdf_docs:
        pdf_reader = PdfReader(pdf)
        for page in pdf_reader.pages:
            # å®¹é”™å¤„ç†ï¼šæœ‰äº›é¡µå¯èƒ½æ˜¯ç©ºçš„
            page_text = page.extract_text()
            if page_text:
                text += page_text
    return text


def get_text_chunks(text):
    text_splitter = RecursiveCharacterTextSplitter(
        chunk_size=1000,
        chunk_overlap=200
    )
    chunks = text_splitter.split_text(text)
    return chunks


def get_vector_store(text_chunks):
    # ä½¿ç”¨æœ¬åœ°è½»é‡çº§æ¨¡å‹
    embeddings = HuggingFaceEmbeddings(model_name="all-MiniLM-L6-v2")
    vector_store = Chroma.from_texts(text_chunks, embedding=embeddings)
    return vector_store


# --- 4. ä¸»é€»è¾‘ ---
if process_button and uploaded_files and api_key:
    with st.spinner("æ­£åœ¨ç–¯ç‹‚é˜…è¯»æ‰€æœ‰æ–‡æ¡£..."):
        # 1. æå–æ‰€æœ‰ PDF çš„æ–‡å­—
        raw_text = get_pdf_text(uploaded_files)

        # 2. åˆ‡ç‰‡
        text_chunks = get_text_chunks(raw_text)

        # 3. å­˜å…¥æ•°æ®åº“
        # æ³¨æ„ï¼šè¿™é‡Œæˆ‘ä»¬ç”¨ st.session_state æŠŠæ•°æ®åº“å­˜èµ·æ¥ï¼Œé˜²æ­¢æ¯æ¬¡æé—®éƒ½é‡æ–°ç®—
        vector_store = get_vector_store(text_chunks)
        st.session_state.vector_store = vector_store

        st.success(f"âœ… å¤„ç†å®Œæˆï¼å…±è¯»å–äº† {len(uploaded_files)} ä¸ªæ–‡ä»¶ã€‚")

# --- 5. èŠå¤©ç•Œé¢ ---
if "vector_store" in st.session_state:
    st.markdown("### ğŸ’¬ å¼€å§‹æé—®")
    user_question = st.text_input("å…³äºè¿™äº›æ–‡æ¡£ï¼Œä½ æƒ³é—®ä»€ä¹ˆï¼Ÿ")

    if user_question:
        llm = ChatOpenAI(
            api_key=api_key,
            base_url="https://api.deepseek.com/v1",
            model_name="deepseek-chat",
            temperature=0.3
        )

        qa_chain = RetrievalQA.from_chain_type(
            llm=llm,
            retriever=st.session_state.vector_store.as_retriever(),
            return_source_documents=True
        )

        response = qa_chain.invoke({"query": user_question})

        st.write("ğŸ¤– **AI å›ç­”:**")
        st.write(response["result"])

        # (å¯é€‰) æ˜¾ç¤ºå‚è€ƒäº†å“ªä¸€æ®µ
        with st.expander("æŸ¥çœ‹å‚è€ƒæ¥æº"):
            for doc in response["source_documents"]:
                st.write(doc.page_content)
else:
    if not uploaded_files:
        st.info("ğŸ‘ˆ è¯·å…ˆåœ¨å·¦ä¾§ä¸Šä¼  PDF æ–‡ä»¶")