import streamlit as st
from pypdf import PdfReader

# === ğŸ›¡ï¸ ç¨³å®šç‰ˆ(0.1.x) å¼•ç”¨ä¿æŒä¸å˜ ===
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain_community.vectorstores import Chroma
from langchain_community.chat_models import ChatOpenAI
from langchain.chains import RetrievalQA
import os

# --- 1. é¡µé¢åŸºç¡€é…ç½® ---
st.set_page_config(page_title="å¤šæ–‡ä»¶ AI åŠ©æ‰‹", layout="wide")
st.title("ğŸ“š å¤šæ–‡æ¡£ AI æ™ºèƒ½é—®ç­”åŠ©æ‰‹")

# --- 2. ä¾§è¾¹æ ï¼šè®¾ç½®ä¸ä¸Šä¼  ---
with st.sidebar:
    st.header("âš™ï¸ è®¾ç½®é¢æ¿")

    # è·å–å¯†é’¥
    api_key = None
    if "DEEPSEEK_API_KEY" in st.secrets:
        api_key = st.secrets["DEEPSEEK_API_KEY"]
        st.success("âœ… äº‘ç«¯å¯†é’¥å·²æ¿€æ´»")
    else:
        api_key = st.text_input("DeepSeek API Key", type="password")

    st.markdown("---")
    uploaded_files = st.file_uploader("ä¸Šä¼  PDF æ–‡ä»¶", type=["pdf"], accept_multiple_files=True)

    # å¤„ç†æŒ‰é’®
    process_button = st.button("ğŸš€ å¼€å§‹å»ºåº“ (ä¸Šä¼ åç‚¹æˆ‘)")

    st.markdown("---")
    # æ·»åŠ ä¸€ä¸ªæ¸…ç©ºå†å²çš„æŒ‰é’®
    if st.button("ğŸ—‘ï¸ æ¸…ç©ºèŠå¤©è®°å½•"):
        st.session_state.messages = []
        st.rerun()


# --- 3. æ ¸å¿ƒå‡½æ•° (é€»è¾‘ä¸å˜) ---
def get_pdf_text(pdf_docs):
    text = ""
    for pdf in pdf_docs:
        pdf_reader = PdfReader(pdf)
        for page in pdf_reader.pages:
            t = page.extract_text()
            if t: text += t
    return text


def get_text_chunks(text):
    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)
    chunks = text_splitter.split_text(text)
    return chunks


def get_vector_store(text_chunks):
    embeddings = HuggingFaceEmbeddings(model_name="all-MiniLM-L6-v2")
    vector_store = Chroma.from_texts(text_chunks, embedding=embeddings)
    return vector_store


# --- 4. ä¸šåŠ¡é€»è¾‘ï¼šå¤„ç†æ–‡ä»¶ ---
if process_button and uploaded_files and api_key:
    with st.spinner("æ­£åœ¨ç–¯ç‹‚é˜…è¯»æ–‡æ¡£ï¼Œè¯·ç¨å€™..."):
        raw_text = get_pdf_text(uploaded_files)
        text_chunks = get_text_chunks(raw_text)
        vector_store = get_vector_store(text_chunks)
        # å­˜å…¥ Session
        st.session_state.vector_store = vector_store
        st.success("âœ… æ–‡æ¡£å·²å¤„ç†å®Œæ¯•ï¼ç°åœ¨å¯ä»¥åœ¨å³ä¾§æé—®äº†ã€‚")

# --- 5. ä¸šåŠ¡é€»è¾‘ï¼šèŠå¤©ç•Œé¢ (é‡ç‚¹ä¿®æ”¹éƒ¨åˆ†) ---

# åˆå§‹åŒ–èŠå¤©å†å² (å¦‚æœè¿˜æ²¡æœ‰çš„è¯)
if "messages" not in st.session_state:
    st.session_state.messages = []

# A. æŠŠå†å²æ¶ˆæ¯ç”»åœ¨å±å¹•ä¸Š
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# B. ç­‰å¾…ç”¨æˆ·è¾“å…¥ (è¿™æ˜¯æ–°çš„è¾“å…¥æ¡†ç»„ä»¶)
if prompt := st.chat_input("è¯·æ ¹æ®æ–‡æ¡£æé—®..."):
    # 1. è¿˜æ²¡ä¼ æ–‡ä»¶å°±æƒ³æé—®ï¼Ÿæ‹¦æˆªï¼
    if "vector_store" not in st.session_state:
        st.error("è¯·å…ˆåœ¨å·¦ä¾§ä¸Šä¼  PDF å¹¶ç‚¹å‡»â€œå¼€å§‹å»ºåº“â€ï¼")
        st.stop()

    # 2. æ˜¾ç¤ºç”¨æˆ·çš„è¯
    st.chat_message("user").markdown(prompt)
    # è®°å…¥å°æœ¬æœ¬
    st.session_state.messages.append({"role": "user", "content": prompt})

    # 3. AI æ€è€ƒå¹¶å›ç­”
    with st.chat_message("assistant"):
        with st.spinner("æ€è€ƒä¸­..."):
            # å‡†å¤‡ LLM
            llm = ChatOpenAI(
                api_key=api_key,
                base_url="https://api.deepseek.com/v1",
                model_name="deepseek-chat",
                temperature=0.3
            )
            # å‡†å¤‡é—®ç­”é“¾
            qa_chain = RetrievalQA.from_chain_type(
                llm=llm,
                retriever=st.session_state.vector_store.as_retriever(),
                return_source_documents=True
            )

            # è·å–ç­”æ¡ˆ
            response = qa_chain.invoke({"query": prompt})
            result = response["result"]

            # æ˜¾ç¤ºç­”æ¡ˆ
            st.markdown(result)

            # (å¯é€‰) æ˜¾ç¤ºæ¥æºï¼ŒæŠ˜å èµ·æ¥ä¸å åœ°æ–¹
            with st.expander("æŸ¥çœ‹å‚è€ƒæ¥æº"):
                for doc in response["source_documents"]:
                    st.write(doc.page_content)

            # è®°å…¥å°æœ¬æœ¬
            st.session_state.messages.append({"role": "assistant", "content": result})